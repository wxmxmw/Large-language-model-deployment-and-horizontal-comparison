
# 大语言模型部署报告

**学号：2351882**  
**姓名：王小萌**

## 一、项目介绍

本次作业围绕大语言模型的部署与应用展开，旨在通过实际操作当前主流开源大语言模型的部署流程及其在实际应用场景中的表现。

项目基于魔搭（ModelScope）平台进行，该平台提供了丰富的模型资源和便捷的部署工具，支持用户快速搭建本地推理环境，并对多个大语言模型进行测试与比较。

在本次项目中，我参考了课程提供的视频教程及相关文档，依次部署了以下三个主流开源大语言模型：

- 通义千问 Qwen-7B-Chat（通义实验室）
- 智谱 ChatGLM3-6B（智谱AI）
- 百川 Baichuan2-7B（百川智能）

部署完成后，执行了多个语义理解相关的测试问题，对各模型的推理能力进行了评估，并在此基础上进行了横向对比分析。

## 二、配置流程

### 1. 注册与资源申请

- 完成魔搭平台注册
- 关联阿里云账号以获取免费的云计算资源

### 2. 环境配置

进入平台后，通过 Terminal 命令行完成以下配置：

1. 安装 Python 环境管理工具 `conda`，并创建独立的虚拟环境  
   > 注：由于平台限流，conda 从官网下载后手动上传安装
   然后运行命令
   ```bash
   bash Miniconda3-latest-Linux-x86_64.sh-b-p /opt/conda
   echo 'export PATH="/opt/conda/bin:$PATH"' >> ~/.bashrc
   source ~/.bashrc
   conda--version
   ```
2. 安装依赖库，包括：
   - 基础依赖：`torch`, `transformers`
   - 模型推理依赖：`sentencepiece`, `tiktoken`, `einops` 等

## 三、大语言模型部署过程

### 1. 模型信息

| 模型名称             | 提供方     | 参数量 | Transformer 版本 | 环境 |
|----------------------|------------|--------|------------------|------|
| Qwen-7B-Chat         | 通义实验室 | 7B     | 4.48.3           | GPU  |
| ChatGLM3-6B          | 智谱AI     | 6B     | 4.33.0           | GPU  |
| Baichuan2-7B         | 百川智能   | 7B     | 4.33.0           | GPU  |

> 注：由于 ChatGLM3-6B 依赖与 transformers 4.48.3 不兼容，重新安装了 4.33.0 版本。

### 2. 模型下载

- 由于存储限制，使用 `git clone` 从 ModelScope 平台下载 Qwen-7B-Chat 和 ChatGLM3-6B
- Baichuan2-13B 因显存不足更换为 Baichuan2-7B
- Baichuan2-7B 使用 ModelScope 接口下载模型权重

```bash

pip install modelscope
git clone https://www.modelscope.cn/qwen/Qwen-7B-Chat.git
pip install transformers==4.33.0
git clone https://www.modelscope.cn/ZhipuAI/chatglm3-6b.git
```


### 3. 模型加载与推理脚本编写

- 编写推理脚本 `run_qwen-7B-Chat.py`， `run_chatglm3-6b.py`使用 `run_Baichuan2-7B-Base.py` 库加载模型并进行推理
- 脚本中使用 `.cuda()` 将模型移动到 GPU 上运行

## 四、模型测试与结果分析

### 测试问题设计

测试问题如下，用于评估模型的语义理解与推理能力：

1. **问题Ⅰ**：请说出以下两句话区别在哪里？
   - 冬天：能穿多少穿多少
   - 夏天：能穿多少穿多少

2. **问题Ⅱ**：请说出以下两句话区别在哪里？
   - 单身狗产生的原因有两个，一是谁都看不上，二是谁都看不上

3. **问题Ⅲ**：他知道我知道你知道他不知道吗？这句话里，到底谁不知道？

4. **问题Ⅳ**：明明明明明白白白喜欢他，可她就是不说。这句话里，明明和白白谁喜欢谁？

5. **问题Ⅴ**：领导：你这是什么意思？  
   小明：没什么意思。意思意思。  
   领导：你这就不够意思了。  
   小明：小意思，小意思。  
   领导：你这人真有意思。  
   小明：其实也没有别的意思。  
   领导：那我就不好意思了。  
   小明：是我不好意思。  
   请问：以上“意思”分别是什么意思。

### 测试结果分析

#### 1. 语义理解能力对比

| 模型名称             | 表现分析 |
|----------------------|----------|
| Qwen-7B-Chat         | 能准确指出两句话分别对应不同季节的穿衣建议，并结合实际生活进行解释 |
| ChatGLM3-6B          | 回答简洁，仅指出季节不同 |
| Baichuan2-7B         | 回答偏离核心，转而讨论南北气候差异 |

#### 2. 逻辑推理能力对比

| 模型名称             | 表现分析 |
|----------------------|----------|
| Qwen-7B-Chat         | 尝试从多个角度分析句子中“知道”与“不知道”的关系，推理过程较为清晰 |
| ChatGLM3-6B          | 指出该句为悖论，并尝试解释其逻辑矛盾之处 |
| Baichuan2-7B         | 回答混乱，未能准确分析句子逻辑结构 |

#### 3. 语言表达能力对比

| 模型名称             | 表现分析 |
|----------------------|----------|
| Qwen-7B-Chat         | 能结合上下文分析出“明明喜欢白白”，并解释合理 |
| ChatGLM3-6B          | 回答准确但解释略显简略 |
| Baichuan2-7B         | 回答模糊，未能准确指出两人之间的关系 |

#### 4. 多义词理解能力对比

| 模型名称             | 表现分析 |
|----------------------|----------|
| Qwen-7B-Chat         | 能逐条解释每个“意思”的具体含义，并结合语境进行分析 |
| ChatGLM3-6B          | 回答准确，但部分解释略显重复 |
| Baichuan2-7B         | 回答泛泛，未能深入分析每个“意思”的具体语义 |

### 5. 综合对比分析

| 维度             | Qwen-7B-Chat | ChatGLM3-6B | Baichuan2-7B      |
|------------------|--------------|-------------|-------------------|
| 推理速度         | 快           | 中等        | 中等              |
| 回答准确性       | 高           | 高          | 中                |
| 语义理解能力     | 强           | 强          | 一般              |
| 多义词处理能力   | 强           | 中          | 弱                |
| 回答流畅度       | 高           | 高          | 中                |

**总结：**
- **Qwen-7B-Chat**：在语义理解和多义词处理方面表现最佳，回答准确且自然；
- **ChatGLM3-6B**：推理速度略慢，但在语义理解方面表现稳定；
- **Baichuan2-7B**：在处理复杂语义和多义词时表现较弱，部分回答不够准确。
